{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from util.prediction import prepare_experiment_dfs, ModelEvaluator, split_train_test\n",
    "\n",
    "df_crawled, df_reg, df_editreg, df_class = prepare_experiment_dfs('data/events/all_events.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gridsearch\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "df_train_full, df_test = split_train_test(df_class, pd.to_datetime('2016-01-01'), 45, 12)\n",
    "param_grid_xgboost_reg = {'max_depth': [4, 5, 6, 10, 15, 20],\n",
    "                          'n_estimators': [10, 100, 500, 1000],\n",
    "                          'learning_rate': [1, 0.5, 0.1, 0.01, 0.001],\n",
    "                          'gamma': [0, 1, 2, 5, 10],\n",
    "                          'reg_lambda': [0, 1, 10],\n",
    "                          'scale_pos_weight': [0.05, 0.1, 1, 2]}\n",
    "param_grid_xgboost_class_viewed = {'max_depth': [4, 5, 6, 10, 15, 20],\n",
    "                                   'n_estimators': [10, 100, 500, 1000],\n",
    "                                   'learning_rate': [0.5, 0.3, 0.1, 0.01, 0.001],\n",
    "                                   'gamma': [0, 1, 2, 5, 10],\n",
    "                                   'reg_lambda': [0.1, 1, 10],\n",
    "                                   'colsample_bytree': [0.1, 0.25, 0.5, 0.75, 1],\n",
    "                                   'scale_pos_weight': [1,\n",
    "                                                        sum(df_train_full.noticed == 0) / sum(\n",
    "                                                            df_train_full.noticed == 1)],\n",
    "                                   'subsample': [0.1, 0.25, 0.5, 0.75, 1]\n",
    "                                   }\n",
    "param_grid_xgboost_class_edited = {'max_depth': [4, 5, 6, 10, 15, 20],\n",
    "                                   'n_estimators': [10, 100, 500, 1000],\n",
    "                                   'learning_rate': [0.5, 0.3, 0.1, 0.01, 0.001],\n",
    "                                   'gamma': [0, 1, 2, 5, 10],\n",
    "                                   'reg_lambda': [0.1, 1, 10],\n",
    "                                   'colsample_bytree': [0.1, 0.25, 0.5, 0.75, 1],\n",
    "                                   'scale_pos_weight': [1,\n",
    "                                                        sum(df_train_full.edited == 0) / sum(\n",
    "                                                            df_train_full.edited == 1)],\n",
    "                                   'subsample': [0.1, 0.25, 0.5, 0.75, 1]\n",
    "                                   }\n",
    "\n",
    "param_grid_rf = {'max_depth': [5, 10, 50, 100, None],\n",
    "                 'n_estimators': [10, 100, 500, 1000],\n",
    "                 'max_features': ['log2', 'sqrt'],\n",
    "                 'min_samples_split': [2, 5, 10],\n",
    "                 'bootstrap': [True, False],\n",
    "                 'min_samples_leaf': [1, 2, 5]}\n",
    "param_grid_svc = {'C': [0.1, 1, 10, 100],\n",
    "                  'kernel': ['rbf', 'poly', 'sigmoid', 'linear'],\n",
    "                  'degree': [1, 2, 3, 5],\n",
    "                  'gamma': ['scale', 'auto'],\n",
    "                  'class_weight': [None, 'balanced']}\n",
    "param_grid_svr = {'C': [0.1, 1, 10, 100],\n",
    "                  'kernel': ['rbf', 'poly', 'sigmoid', 'linear'],\n",
    "                  'degree': [1, 2, 3, 5],\n",
    "                  'gamma': ['scale', 'auto'],\n",
    "                  'epsilon': [0, 0.01, 0.1, 1]}\n",
    "\n",
    "param_grid_negative_binomial = None  # needs no grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def save_object(obj, filename, path='crossval_results'):\n",
    "    if obj.gs_res:\n",
    "        try:\n",
    "            if obj.gs_res.best_estimator_:\n",
    "                with open(f'{path}/{filename}.pkl', 'wb') as outp:  # Overwrites any existing file.\n",
    "                    pickle.dump(obj.gs_res, outp, pickle.HIGHEST_PROTOCOL)\n",
    "        except:\n",
    "            print(f'No estimator trained for {filename}. Not saving')\n",
    "    else:\n",
    "        print(f'No estimator trained for {filename}. Not saving')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01 00:00:00 2019-01-01 00:00:00 2020-01-01 00:00:00\n",
      "2016-01-01 00:00:00 2020-01-01 00:00:00 2021-01-01 00:00:00\n",
      "2016-01-01 00:00:00 2019-01-01 00:00:00 2020-01-01 00:00:00\n",
      "2016-01-01 00:00:00 2020-01-01 00:00:00 2021-01-01 00:00:00\n",
      "2016-01-01 00:00:00 2019-01-01 00:00:00 2020-01-01 00:00:00\n",
      "2016-01-01 00:00:00 2020-01-01 00:00:00 2021-01-01 00:00:00\n",
      "2016-01-01 00:00:00 2019-01-01 00:00:00 2020-01-01 00:00:00\n",
      "2016-01-01 00:00:00 2020-01-01 00:00:00 2021-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "n_jobs = 162\n",
    "n_iter = 1000\n",
    "\n",
    "# ================ XGB ========================\n",
    "# noticed\n",
    "grid_xgb_viewed_noreg = ModelEvaluator(XGBClassifier(n_jobs=n_jobs), df_class, 'noticed', 'f1_micro',\n",
    "                                       params=param_grid_xgboost_class_viewed, factor_cols=['code', 'cat'])\n",
    "grid_xgb_viewed_noreg.random_search(n_jobs=1, n_iter=n_iter)\n",
    "grid_xgb_viewed_noreg.gs_res = grid_xgb_viewed_noreg.rs_res\n",
    "save_object(grid_xgb_viewed_noreg, 'noreg_viewed_xgb')\n",
    "\n",
    "# edited\n",
    "grid_xgb_edit_noreg = ModelEvaluator(XGBClassifier(n_jobs=n_jobs), df_class, 'edited', 'f1_micro',\n",
    "                                     params=param_grid_xgboost_class_edited, factor_cols=['code', 'cat'])\n",
    "grid_xgb_edit_noreg.random_search(n_jobs=1, n_iter=n_iter)\n",
    "grid_xgb_edit_noreg.gs_res = grid_xgb_edit_noreg.rs_res\n",
    "save_object(grid_xgb_edit_noreg, 'noreg_edited_xgb')\n",
    "\n",
    "# views\n",
    "grid_xgb_views7sum_noreg = ModelEvaluator(XGBRegressor(n_jobs=n_jobs), df_reg, 'views_7_sum_log',\n",
    "                                          'neg_mean_squared_error', params=param_grid_xgboost_reg,\n",
    "                                          factor_cols=['code', 'cat'])\n",
    "grid_xgb_views7sum_noreg.random_search(n_jobs=1, n_iter=n_iter)\n",
    "grid_xgb_views7sum_noreg.gs_res = grid_xgb_views7sum_noreg.rs_res\n",
    "save_object(grid_xgb_views7sum_noreg, 'noreg_views_xgb')\n",
    "\n",
    "# edits\n",
    "grid_xgb_edits7sum_noreg = ModelEvaluator(XGBRegressor(n_jobs=n_jobs), df_editreg, 'edits_7_sum_log',\n",
    "                                          'neg_mean_squared_error', params=param_grid_xgboost_reg,\n",
    "                                          factor_cols=['code', 'cat'])\n",
    "grid_xgb_edits7sum_noreg.random_search(n_jobs=1, n_iter=n_iter)\n",
    "grid_xgb_edits7sum_noreg.gs_res = grid_xgb_edits7sum_noreg.rs_res\n",
    "save_object(grid_xgb_edits7sum_noreg, 'noreg_edits_xgb')\n",
    "\n",
    "# ================ RF ========================\n",
    "grid_rf_edited_noreg = ModelEvaluator(RandomForestClassifier(n_jobs=-1), df_class, 'edited', 'f1_micro',\n",
    "                                      params=param_grid_rf, factor_cols=['code', 'cat'])\n",
    "grid_rf_edits7sum_noreg = ModelEvaluator(RandomForestRegressor(n_jobs=-1), df_editreg, 'edits_7_sum_log',\n",
    "                                         'neg_mean_squared_error', params=param_grid_rf, factor_cols=['code', 'cat'])\n",
    "grid_rf_viewed_noreg = ModelEvaluator(RandomForestClassifier(n_jobs=-1), df_class, 'noticed', 'f1_micro',\n",
    "                                      params=param_grid_rf, factor_cols=['code', 'cat'])\n",
    "grid_rf_views7sum_noreg = ModelEvaluator(RandomForestRegressor(n_jobs=-1), df_reg, 'views_7_sum_log',\n",
    "                                         'neg_mean_squared_error', params=param_grid_rf, factor_cols=['code', 'cat'])\n",
    "\n",
    "grid_rf_viewed_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_rf_viewed_noreg.gs_res = grid_rf_viewed_noreg.rs_res\n",
    "save_object(grid_rf_viewed_noreg, 'noreg_viewed_rf')\n",
    "\n",
    "grid_rf_edited_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_rf_edited_noreg.gs_res = grid_rf_edited_noreg.rs_res\n",
    "save_object(grid_rf_edited_noreg, 'noreg_edited_rf')\n",
    "\n",
    "grid_rf_views7sum_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_rf_views7sum_noreg.gs_res = grid_rf_views7sum_noreg.rs_res\n",
    "save_object(grid_rf_views7sum_noreg, 'noreg_views_rf')\n",
    "\n",
    "grid_rf_edits7sum_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_rf_edits7sum_noreg.gs_res = grid_rf_edits7sum_noreg.rs_res\n",
    "save_object(grid_rf_edits7sum_noreg, 'noreg_edits_rf')\n",
    "\n",
    "# ================ SVC ========================\n",
    "grid_svc_views7sum_noreg = ModelEvaluator(SVR(), df_reg, 'views_7_sum_log', 'neg_mean_squared_error',\n",
    "                                          params=param_grid_svr, factor_cols=['code', 'cat'])\n",
    "grid_svc_edits7sum_noreg = ModelEvaluator(SVR(), df_reg, 'edits_7_sum_log', 'neg_mean_squared_error',\n",
    "                                          params=param_grid_svr, factor_cols=['code', 'cat'])\n",
    "grid_svc_edit_noreg = ModelEvaluator(SVC(), df_class, 'edited', 'f1_micro', params=param_grid_svc,\n",
    "                                     factor_cols=['code', 'cat'])\n",
    "grid_svc_viewed_noreg = ModelEvaluator(SVC(), df_class, 'noticed', 'f1_micro', params=param_grid_svc,\n",
    "                                       factor_cols=['code', 'cat'])\n",
    "\n",
    "grid_svc_edits7sum_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_svc_edits7sum_noreg.gs_res = grid_svc_edits7sum_noreg.rs_res\n",
    "save_object(grid_svc_edits7sum_noreg, 'noreg_views_svc')\n",
    "\n",
    "grid_svc_edits7sum_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_svc_edits7sum_noreg.gs_res = grid_svc_edits7sum_noreg.rs_res\n",
    "save_object(grid_svc_edits7sum_noreg, 'noreg_views_svc')\n",
    "\n",
    "grid_svc_edit_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_svc_edit_noreg.gs_res = grid_svc_edit_noreg.rs_res\n",
    "save_object(grid_svc_edit_noreg, 'noreg_edited_svc')\n",
    "\n",
    "grid_svc_viewed_noreg.random_search(n_jobs=-1, n_iter=n_iter)\n",
    "grid_svc_viewed_noreg.gs_res = grid_svc_viewed_noreg.rs_res\n",
    "save_object(grid_svc_viewed_noreg, 'noreg_viewed_svc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}