{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Article Category Specific Features: Disasters by Deaths and GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "from util.prediction import transform_vars_for_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving deaths and injured from WikiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: You do not have to run this, you can just load the prepared dataframe here:\n",
    "df_disasters = pd.read_csv('data/events/df_disasters.csv.gz')\n",
    "df_disasters = transform_vars_for_regression(df_disasters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data from WikiData\n",
    "This is not necessary if you upload the dataframe above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crawled = pd.read_csv('data/events/all_events.csv.gz').drop_duplicates().drop(['Unnamed: 0'], axis=1)\n",
    "df_disasters = df_crawled[df_crawled.cat == 'disaster']\n",
    "df_disasters = transform_vars_for_regression(df_disasters)\n",
    "\n",
    "# Retrieve disaster info from Wikidata\n",
    "dict_jsons = {}\n",
    "for qid in df_disasters.event_id.unique():\n",
    "    rec_json = rq.get(f'https://www.wikidata.org/wiki/Special:EntityData/{qid}.json').json()\n",
    "    dict_jsons[qid] = rec_json\n",
    "\n",
    "# Extract PIDS\n",
    "#  number of survivors (P1561) \n",
    "#  number of injured (P1339) \n",
    "#  number of deaths (P1120) \n",
    "def get_dataval(entity, property_id):\n",
    "    if 'claims' in entity:\n",
    "        entity = entity['claims']\n",
    "        if property_id in entity:\n",
    "            dataval = entity[property_id][0]['mainsnak']\n",
    "            if 'datavalue' in dataval:\n",
    "                return int(dataval['datavalue']['value']['amount'].replace('+', ''))\n",
    "            else:\n",
    "                return None # Unknown\n",
    "    return None\n",
    "\n",
    "pd_data = []\n",
    "for key, vals in dict_jsons.items():\n",
    "    entity = list(vals['entities'].values())[0]\n",
    "    survivors, injured, deaths = \\\n",
    "        get_dataval(entity, 'P1561'), get_dataval(entity, 'P1339'), get_dataval(entity, 'P1120')\n",
    "    pd_data.append([key, survivors, injured, deaths])\n",
    "df_casualties = pd.DataFrame(pd_data, columns=['event_id', 'survivors', 'injured', 'deaths'])\n",
    "\n",
    "# Merge DF\n",
    "df_disasters = df_disasters.merge(df_casualties.fillna(0), on='event_id')\n",
    "df_disasters = transform_vars_for_regression(df_disasters)\n",
    "df_disasters['casualties'] = df_disasters.deaths + df_disasters.injured\n",
    "df_disasters['deaths_log'] = np.log1p(df_disasters.deaths)\n",
    "df_disasters['casualties_log'] = np.log1p(df_disasters.casualties)\n",
    "df_disasters['injured_log'] = np.log1p(df_disasters.injured)\n",
    "df_disasters.to_csv('data/events/df_disasters_wikidata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fit XGB Tree and Compute SHAP values for Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from util.prediction import ModelEvaluator\n",
    "import shap\n",
    "from util.plot import plot_disaster_results, build_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_disasters_reg = df_disasters[df_disasters.views_7_sum > 10]\n",
    "df_disasters_reg['views_7_sum_log'] = np.log1p(df_disasters_reg.views_7_sum)\n",
    "df_disasters_reg.event_date = pd.to_datetime(df_disasters_reg.event_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_co...\n",
       "                                          n_estimators=100, n_jobs=144,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None,\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=100, n_jobs=1,\n",
       "                   param_distributions={'gamma': [0, 1, 2, 5, 10],\n",
       "                                        'learning_rate': [1, 0.5, 0.1, 0.01,\n",
       "                                                          0.001],\n",
       "                                        'max_depth': [4, 5, 6, 10, 15, 20],\n",
       "                                        'n_estimators': [10, 100, 500, 1000],\n",
       "                                        'reg_lambda': [0, 1, 10],\n",
       "                                        'scale_pos_weight': [0.05, 0.1, 1, 2]},\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model via random search\n",
    "param_grid_xgboost_reg = {'max_depth': [4, 5, 6, 10, 15, 20],\n",
    "                          'n_estimators': [10, 100, 500, 1000],\n",
    "                          'learning_rate': [1, 0.5, 0.1, 0.01, 0.001],\n",
    "                          'gamma': [0, 1, 2, 5, 10],\n",
    "                          'reg_lambda': [0, 1, 10],\n",
    "                          'scale_pos_weight': [0.05, 0.1, 1, 2]}\n",
    "\n",
    "xgb_disasters = ModelEvaluator(XGBRegressor(n_jobs=144), df_disasters_reg, 'views_7_sum_log',  'neg_mean_squared_error', params=param_grid_xgboost_reg,\n",
    "                               cont_cols = ['GDP_pc_log', 'deaths_log', 'country_articles_log', 'population_log', 'cat_articles_log', 'view_country_article_log', 'views_baseline_log'],\n",
    "                               factor_cols=['code'])\n",
    "xgb_disasters.grid_search(n_jobs=1)\n",
    "\n",
    "xgb_disasters_simple = ModelEvaluator(XGBRegressor(n_jobs=144), df_disasters_reg, 'views_7_sum_log', 'neg_mean_squared_error', params=param_grid_xgboost_reg, cont_cols = ['GDP_pc_log', 'deaths_log'], factor_cols=['code'])\n",
    "xgb_disasters_simple.grid_search(n_jobs=1)\n",
    "\n",
    "xgb_disasters.retrain_full()\n",
    "xgb_disasters_simple.retrain_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_full = pd.concat([xgb_disasters.df_train_full, xgb_disasters.df_test])[xgb_disasters.encoded_columns]\n",
    "explainer = shap.Explainer(xgb_disasters.full_model)\n",
    "shap_values = explainer(df_full)\n",
    "shap_interaction = explainer.shap_interaction_values(df_full)\n",
    "plot_disaster_results(df_full, shap_values, shap_interaction, save_path=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_full = pd.concat([xgb_disasters_simple.df_train_full, xgb_disasters_simple.df_test])[xgb_disasters_simple.encoded_columns]\n",
    "explainer = shap.Explainer(xgb_disasters_simple.full_model)\n",
    "shap_values = explainer(df_full)\n",
    "shap_interaction = explainer.shap_interaction_values(df_full)\n",
    "plot_disaster_results(df_full, shap_values, shap_interaction, save_path=None,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cmp = build_colormap('GDP pc. (log)', (df_full['GDP pc. (log)'].min(), df_full['GDP pc. (log)'].max()), cmap='viridis', labelpad=-13, horizontal=True, adjust_limits=False, save_path='figures/disasters/deaths_col_cm_horizontal.pdf', ticks=[5.0, 8, 11.])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}